{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anurag/miniconda3/envs/ul_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "from utils import *\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"biolinkbert\"\n",
    "\n",
    "MODEL_PATH = \"best_model/\"+MODEL+\"/\"\n",
    "FORGET_DETAILS_PATH = \"data/forget_set.json\"\n",
    "\n",
    "mlb, classes = get_classes_mlb()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "test_loader, val_loader, forget_details = load_val_test_loaders(FORGET_DETAILS_PATH, tokenizer, mlb)\n",
    "\n",
    "criterion = SafeWeightedBCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a37e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNLEARNED_MODEL_PATH = \"unlearned/\"+MODEL+\"/adv_imp/\"\n",
    "\n",
    "WEIGHT_LAMB = 0.5\n",
    "FORGET_LAMB = 0.3\n",
    "RETAIN_LAMB = 0.7\n",
    "\n",
    "for UNLEARN_K in forget_details:\n",
    "    retain_score = 0\n",
    "    forget_score = 0\n",
    "    test_score = 0\n",
    "    org_forget_score = 0\n",
    "    org_retain_score = 0\n",
    "\n",
    "    for fold in forget_details[UNLEARN_K]:\n",
    "        least_forget_score = 1.0\n",
    "        unlearned_model_path = UNLEARNED_MODEL_PATH+UNLEARN_K+\"/\"+fold\n",
    "        forget_loader, retain_loader, df_forget, df_retain = load_retain_forget_loaders(forget_details[UNLEARN_K][fold], tokenizer, mlb)\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=UNLEARN_LR)\n",
    "\n",
    "        # Save original params (detach clones)\n",
    "        origin_params = {}\n",
    "        for n, p in named_parameters_dict(model).items():\n",
    "            origin_params[n] = p.detach().clone()\n",
    "\n",
    "        # Estimate importance on the forget_loader (use all forget samples or set num_samples)\n",
    "        print(\"Estimating parameter importance (this may take a while)...\")\n",
    "        params_importance = estimate_parameter_importance(forget_loader, model, device)\n",
    "\n",
    "        # Perform Adversairial attack and generate adversarial samples of forget set\n",
    "        adv_loader = load_adv_loader(model, forget_loader, device)\n",
    "\n",
    "        forget_metrics = test(model, forget_loader, device)\n",
    "        retain_metrics = test(model, retain_loader, device)\n",
    "        org_forget_score += forget_metrics[\"score\"]\n",
    "        org_retain_score += retain_metrics[\"score\"]\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            total_adv_loss = 0\n",
    "            total_forget_loss = 0\n",
    "            total_batches = len(forget_loader)\n",
    "            samples = 0\n",
    "\n",
    "            for i, (forget_batch, adv_batch) in enumerate(zip(forget_loader, adv_loader)):\n",
    "                forget_input_ids = forget_batch['input_ids'].to(device)\n",
    "                forget_attention_mask = forget_batch['attention_mask'].to(device)\n",
    "                forget_labels = forget_batch['labels'].to(device)\n",
    "                adv_embeds = adv_batch['embeds'].to(device)\n",
    "                adv_attention_mask = adv_batch['attention_mask'].to(device)\n",
    "                adv_labels = adv_batch['labels'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                forget_outputs = model(input_ids=forget_input_ids, attention_mask=forget_attention_mask)\n",
    "                adv_outputs = model(inputs_embeds=adv_embeds, attention_mask=adv_attention_mask)\n",
    "\n",
    "                forget_loss = criterion(forget_outputs.logits, forget_labels)\n",
    "                adv_loss = criterion(adv_outputs.logits, adv_labels)\n",
    "                reg_loss = parameter_regularization_loss(model, origin_params, params_importance)\n",
    "                loss = RETAIN_LAMB*adv_loss - FORGET_LAMB*forget_loss + WEIGHT_LAMB*reg_loss\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "            forget_metrics = test(model, forget_loader, device)\n",
    "            if(forget_metrics[\"score\"] < least_forget_score):\n",
    "                least_forget_score = forget_metrics[\"score\"]\n",
    "                model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                model_to_save.save_pretrained(unlearned_model_path)\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(unlearned_model_path)\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        retain_metrics = test(model, retain_loader, device)\n",
    "        test_metrics = test(model, test_loader, device)\n",
    "\n",
    "        forget_score += least_forget_score\n",
    "        retain_score += retain_metrics[\"score\"]\n",
    "        test_score += test_metrics[\"score\"]\n",
    "\n",
    "    avg_forget_score = forget_score/TRIALS\n",
    "    avg_retain_score = retain_score/TRIALS\n",
    "    avg_test_score = test_score/TRIALS\n",
    "    avg_org_forget_score = org_forget_score/TRIALS\n",
    "    avg_org_retain_score = org_retain_score/TRIALS\n",
    "\n",
    "    print(f\"\\nFinal scores of Unlearn_K: {UNLEARN_K}\")\n",
    "    print(f\"Avg Forget score (before unlearning): {avg_org_forget_score:.4f}\")\n",
    "    print(f\"Avg Retain score (before unlearning): {avg_org_retain_score:.4f}\")\n",
    "    print(f\"Avg Forget Score: {avg_forget_score:.4f}\")\n",
    "    print(f\"Avg Retain Score: {avg_retain_score:.4f}\")\n",
    "    print(f\"Avg Test Score: {avg_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"biolinkbert\"\n",
    "\n",
    "MODEL_PATH = \"best_model/\"+MODEL+\"/\"\n",
    "UNLEARNED_MODEL_PATH = \"unlearned/\"+MODEL+\"/ga_with_retain/\"\n",
    "FORGET_DETAILS_PATH = \"data/forget_set.json\"\n",
    "\n",
    "LAMBDA = 0.4\n",
    "\n",
    "for UNLEARN_K in forget_details:\n",
    "    retain_score = 0\n",
    "    forget_score = 0\n",
    "    test_score = 0\n",
    "    org_forget_score = 0\n",
    "    org_retain_score = 0\n",
    "    for fold in forget_details[UNLEARN_K]:\n",
    "        least_forget_score = 1.0\n",
    "        unlearned_model_path = UNLEARNED_MODEL_PATH+UNLEARN_K+\"/\"+fold\n",
    "        forget_loader, retain_loader, df_forget, df_retain = load_retain_forget_loaders(forget_details[UNLEARN_K][fold], tokenizer, mlb)\n",
    "        sampled_retain_loader, sampled_retain_labels = get_sampled_retain_loader(df_retain, tokenizer, mlb, UNLEARN_K, fold)   \n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=UNLEARN_LR)\n",
    "\n",
    "        forget_metrics = test(model, forget_loader, device)\n",
    "        retain_metrics = test(model, retain_loader, device)\n",
    "        org_forget_score += forget_metrics[\"score\"]\n",
    "        org_retain_score += retain_metrics[\"score\"]\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            total_forget_loss = 0\n",
    "            total_batches = len(forget_loader)\n",
    "            samples = 0\n",
    "            \n",
    "            for i, (forget_batch, retain_batch) in enumerate(zip(forget_loader, sampled_retain_loader)):\n",
    "                forget_input_ids = forget_batch['input_ids'].to(device)\n",
    "                forget_attention_mask = forget_batch['attention_mask'].to(device)\n",
    "                forget_labels = forget_batch['labels'].to(device)\n",
    "                retain_input_ids = retain_batch['input_ids'].to(device)\n",
    "                retain_attention_mask = retain_batch['attention_mask'].to(device)\n",
    "                retain_labels = retain_batch['labels'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                forget_outputs = model(input_ids=forget_input_ids, attention_mask=forget_attention_mask)\n",
    "                retain_outputs = model(input_ids=retain_input_ids, attention_mask=retain_attention_mask)\n",
    "                    \n",
    "                retain_loss = criterion(retain_outputs.logits, retain_labels)\n",
    "                forget_loss = criterion(forget_outputs.logits, forget_labels)\n",
    "                loss = (1-LAMBDA)*retain_loss - LAMBDA*forget_loss\n",
    "                loss.backward()\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "                optimizer.step()\n",
    "\n",
    "            avg_train_loss = train_loss/samples  \n",
    "            avg_forget_loss = total_forget_loss/samples\n",
    "            \n",
    "            forget_metrics = test(model, forget_loader, device)\n",
    "            if(forget_metrics[\"score\"] < least_forget_score):\n",
    "                least_forget_score = forget_metrics[\"score\"]\n",
    "                model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                model_to_save.save_pretrained(unlearned_model_path)\n",
    "                print(\"Model saved\")\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(unlearned_model_path)\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        retain_metrics = test(model, retain_loader, device)\n",
    "        test_metrics = test(model, test_loader, device)\n",
    "\n",
    "        forget_score += least_forget_score\n",
    "        retain_score += retain_metrics[\"score\"]\n",
    "        test_score += test_metrics[\"score\"]\n",
    "\n",
    "    avg_forget_score = forget_score/TRIALS\n",
    "    avg_retain_score = retain_score/TRIALS\n",
    "    avg_test_score = test_score/TRIALS\n",
    "    avg_org_forget_score = org_forget_score/TRIALS\n",
    "    avg_org_retain_score = org_retain_score/TRIALS\n",
    "\n",
    "    print(f\"\\nFinal scores of Unlearn_K: {UNLEARN_K}\")\n",
    "    print(f\"Avg Forget score (before unlearning): {avg_org_forget_score:.4f}\")\n",
    "    print(f\"Avg Retain score (before unlearning): {avg_org_retain_score:.4f}\")\n",
    "    print(f\"Avg Forget Score: {avg_forget_score:.4f}\")\n",
    "    print(f\"Avg Retain Score: {avg_retain_score:.4f}\")\n",
    "    print(f\"Avg Test Score: {avg_test_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ul_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
